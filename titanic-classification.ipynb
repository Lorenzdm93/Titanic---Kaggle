{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Titanic Project - Kaggle\n## Use a dataset from the titanic giving information about passengers in order to predict weather they will survive or not.","metadata":{}},{"cell_type":"code","source":"#main libraries\nimport os\nimport re\nimport pickle\nimport numpy as np\nimport pandas as pd\n\n#visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly \nimport plotly.graph_objs as go\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks as cf\n\n#machine learning libraries:\nfrom sklearn.model_selection import StratifiedKFold, cross_validate, cross_val_score, train_test_split\nfrom sklearn.preprocessing  import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import KNNImputer, IterativeImputer\nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import TomekLinks,RandomUnderSampler,NearMiss\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.metrics import roc_auc_score, confusion_matrix,plot_confusion_matrix,cohen_kappa_score,accuracy_score,recall_score,precision_score,f1_score,classification_report\n\n# Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 300)\n\n# You can go offline on demand by using\ncf.go_offline() \n\n# To connect java script to your notebook\ninit_notebook_mode(connected=False)\n\n# set some display options:\nplt.rcParams['figure.dpi'] = 100\ncolors = px.colors.qualitative.Prism\npio.templates.default = \"plotly_white\"\n\n# see our files:\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/titanic/train.csv')\ntest=pd.read_csv('/kaggle/input/titanic/test.csv')\ngender=pd.read_csv('/kaggle/input/titanic/gender_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train.columns = [x.lower() for x in train.columns]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Descriptive Statistics - Glancing from above","metadata":{}},{"cell_type":"code","source":"data=train\ndata.head(20)\ndata.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next: Checking for NaNs. Notice that three columns have nulls.","metadata":{}},{"cell_type":"code","source":"print(data.isnull().sum())\n\n#visuaize the null values in each column\nplt.figure(figsize=(20,6));\nsns.heatmap(data.isnull(), cmap='viridis');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['target'] = data['Survived'].map({1:'Survived',0:'Not Survived'})\ndata['sex'] = data['Sex'].apply(lambda x:x.title()) #title makes the first letter of each word uppercase","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datanum=data.select_dtypes(include=np.number)\ndatanum","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data=data.drop('Name',axis=1)\ndata=data.drop('PassengerId',axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis EDA","metadata":{}},{"cell_type":"markdown","source":"## Getting a sense of the data, Data Exploration","metadata":{}},{"cell_type":"code","source":"sns.set(style='whitegrid', context='talk', palette='viridis');\nsns.pairplot(datanum)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlations_matrix= datanum.corr()\nmask = np.zeros_like(correlations_matrix)\nmask[np.triu_indices_from(mask)] = True\nfig, ax = plt.subplots(figsize=(10, 8))\nax = sns.heatmap(correlations_matrix, mask=mask, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize columns have highest Skewness\nfig, axes = plt.subplots(1,3, figsize=(20, 8));\nfig.suptitle('Highest Skewness', fontsize=20);\n\nsns.kdeplot(datanum['Fare'], ax=axes[0],hue=datanum['Survived']);\nsns.kdeplot(datanum['SibSp'], ax=axes[1],hue=datanum['Survived']);\nsns.kdeplot(datanum['Parch'], ax=axes[2],hue=datanum['Survived']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining three functions for plotting ","metadata":{}},{"cell_type":"code","source":"# lets define a function to plot a bar plot easily\n\ndef bar_plot(df,x,x_title,y,title,colors=None,text=None):\n    fig = px.bar(x=x,\n                 y=y,\n                 text=text,\n                 labels={\"index\": x_title},                             # replaces default labels by column name\n                 data_frame=df,\n                 color=colors,\n                 barmode='group',\n                 template=\"simple_white\",\n                 color_discrete_sequence=px.colors.qualitative.Prism)\n    \n    texts = [temp[col].values for col in y]\n    for i, t in enumerate(texts):\n        fig.data[i].text = t\n        fig.data[i].textposition = 'inside'\n        \n    fig['layout'].title=title\n\n    for trace in fig.data:\n        trace.name = trace.name.replace('_',' ').capitalize()\n\n    fig.update_yaxes(tickprefix=\"\", showgrid=True)\n\n    fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets create a function to plot a multi-violin easily\n\ndef multi_violin(df,iter_col,dist_col,color_col='survived'):\n    if len(df[color_col].unique())!= 2:\n        return 'Maximun number of unique values in the color columns is 2'\n    i = 0\n    data = []\n    for ite in df[iter_col]:#multi_violin(df=df.dropna(),iter_col='pclass',dist_col='age',color_col='target')\n#         print(df[df[color_col]==df[color_col].unique().tolist()[0]][dist_col])\n        data.append(go.Violin(x=df[df[iter_col]==ite][iter_col],\n                              y=df[df[color_col]==df[color_col].unique().tolist()[0]][dist_col],\n                              name=str(df[color_col].unique().tolist()[0]),\n                              jitter=0,\n                              meanline={'visible':True},\n                              line={\"color\": '#F78181'},\n                              side='negative',\n                              marker=dict(color= '#81F781'),\n                              showlegend=(i==0)))\n\n        data.append(go.Violin(x=df[df[iter_col]==ite][iter_col],\n                              y=df[df['target']==df['target'].unique().tolist()[1]]['age'],\n                               name=str(df[color_col].unique().tolist()[1]),\n                               jitter=0,\n                               meanline={'visible':True},\n                               line={\"color\": '#00FF40'},\n                               side='positive',\n                               marker=dict(color= '#81F781'),\n                               showlegend=(i==0)))\n        i+=1\n\n\n    layout = dict(title='Distribution of {} column for each {} colored by {}'.format(dist_col.replace('_',' ').title(),\n                                                                                     iter_col.replace('_',' ').title(),\n                                                                                     color_col.replace('_',' ').title()),\n                  width=1000,height=600,\n                  yaxis=dict(title='Distribution',titlefont=dict(size=20)))\n\n    iplot(dict(data=data,layout=layout))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a function to plot multi box plots easily\n\ndef multi_box(df,cat_col,dist_col,color_col):\n    \n    y = []\n    x = []\n    \n    if len(df[color_col].unique())!= 2:\n        return 'Maximun number of unique values in the color columns is 2'\n    \n    for c in set(df[cat_col].unique().tolist()):\n        for t in set(df[color_col].unique()):\n            y.append(df[(df[cat_col]==c) & (df[color_col]==t)][dist_col].values)\n            x.append(str(c)+' ('+str(t)+')')        \n\n    colors = ['rgba(251, 43, 43, 0.5)', 'rgba(125, 251, 137, 0.5)', \n              'rgba(251, 43, 43, 0.5)', 'rgba(125, 251, 137, 0.5)', \n              'rgba(251, 43, 43, 0.5)', 'rgba(125, 251, 137, 0.5)',\n              'rgba(251, 43, 43, 0.5)', 'rgba(125, 251, 137, 0.5)', \n              'rgba(251, 43, 43, 0.5)', 'rgba(125, 251, 137, 0.5)', \n              'rgba(251, 43, 43, 0.5)', 'rgba(125, 251, 137, 0.5)']\n\n    traces = []\n\n    for xd, yd, cls in zip(x, y, colors[:2*len(df[cat_col].unique())]):\n            traces.append(go.Box(y=yd,\n                                 name=xd,\n                                 boxpoints='all',\n                                 jitter=0.5,\n                                 whiskerwidth=0.2,\n                                 fillcolor=cls,\n                                 marker=dict(size=2),\n                                 line=dict(width=1)))\n\n    layout = go.Layout(title='{} distribution colord by {} grouped by {}'.format(dist_col.title(),\n                                                                                 color_col.title(),\n                                                                                 cat_col.title()),\n        xaxis=dict(title=cat_col,\n                   titlefont=dict(size=16)),\n        \n        yaxis=dict(title='Distribution',\n                   autorange=True,\n                   showgrid=True,\n                   zeroline=True,\n                   dtick=5,\n                   gridcolor='rgb(255, 255, 255)',\n                   gridwidth=1,\n                   zerolinecolor='rgb(255, 255, 255)',\n                   zerolinewidth=2,\n                   titlefont=dict(\n                   size=16)),\n        \n        margin=dict(l=40,\n                    r=30,\n                    b=80,\n                    t=100),\n        \n        paper_bgcolor='rgb(255, 255, 255)',\n        plot_bgcolor='rgb(255, 243, 192)',\n        showlegend=False)\n\n    fig = go.Figure(data=traces, layout=layout)\n    iplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical Variables ","metadata":{}},{"cell_type":"markdown","source":"### Sex \nThe plot shows that most passengers are male, female have a higher chances of survival.","metadata":{}},{"cell_type":"code","source":"temp = pd.DataFrame()\n\nfor sex in pd.unique(data['Sex']).tolist():\n    temp[sex] = data[data['Sex']==sex]['target'].value_counts()\n    \ntemp = temp.rename(columns={0:'Female',1:'Male'}).T\ntemp['Total sum'] = temp.sum(axis=1)\n\nbar_plot(temp.reset_index(),\n         'index',\n         'Sex',\n         ['Total sum','Survived','Not Survived'],\n         title='Survived and Not-survived grouped by sex')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Passenger Class\n\nGraph shows that most passengers were in class 3 and they are the ones less likely to survive (speculation: probably due to location of cabins?)","metadata":{}},{"cell_type":"code","source":"temp = pd.DataFrame()\n\nfor p in pd.unique(data['Pclass']).tolist():\n    temp[p] = data[data['Pclass']==p]['target'].value_counts()\n    \ntemp = temp.rename(columns={1:'Class 1',2:'Class 2', 3:'Class 3'}).T\ntemp['Total sum'] = temp.sum(axis=1)\n\nbar_plot(temp.reset_index(),\n         'index',\n         'Pclass',\n         ['Total sum','Survived','Not Survived'],\n         title='Survived and Not-survived grouped by Pclass')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Family Counts\n\nSolo travellers have very low chances of survival, while people with 2-4 family members are more likely to survive. Beyond 4, more family members do not increase likelihood of survival.","metadata":{}},{"cell_type":"code","source":"#engineer a new column for the total number of family (Passenger )\ndata['family count'] = data['Parch']+data['SibSp']+1 \ndata['family count'] = data['family count'].astype(int)\n\ndel data['Parch']\ndel data['SibSp']\n\ntemp = pd.crosstab(index=data['family count'],columns=data['target']).reset_index()\n\ntemp['Total sum'] = temp.sum(axis=1)\n\nbar_plot(temp,\n         'family count',\n         'Family number',\n         ['Total sum','Survived','Not Survived'],\n         title='Survived and Not-survived grouped by Family number')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Embarked\n\nRoughly 70% of people embarked from Southampton. They are less likely to survive.","metadata":{}},{"cell_type":"code","source":"data['Embarked'].value_counts().to_frame().rename(columns={'Embarked':'Total Count'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = pd.DataFrame()\n\nfor e in data['Embarked'].unique().tolist():\n    temp[e] = data[data['Embarked']==e]['target'].value_counts()\n    \ntemp = temp.T.rename(index={'S':'Southampton','C':'Cherbourg','Q':'Queenstown'})\ntemp['Total sum'] = temp.sum(axis=1)\n\nbar_plot(temp.reset_index(),\n         'index',\n         'Embarked',\n         ['Total sum','Survived','Not Survived'],\n         title='Survived and Not-survived grouped by Embarked column')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Numerical Variables ","metadata":{}},{"cell_type":"markdown","source":"### Age\nIt is not very informative and if we need to use it as predictor, we will need quite some feature extraction and engineering","metadata":{}},{"cell_type":"code","source":"#enginerring a new column age_category where nans are replaced with the age mean and age is binned into ranges.\ndata['age_category'] = pd.cut(data['Age'].fillna(data['Age'].mean()).astype(int), bins=[-1,11,18,22,27,33,40,66,100],\n                            labels=[\"<=11\",\"11-18\",\"19-22\",\"23-27\",\"28-33\",\"34-40\",\"41-66\",\">=67\"])\n\ntemp = pd.DataFrame()\nfor age in data['age_category'].unique().tolist():\n    temp[age] = data[data['age_category']==age]['target'].value_counts()\n\ntemp = temp.T.reset_index()\ntemp['Total sum'] = temp.sum(axis=1)\n\nbar_plot(temp.reset_index(),\n         'index',\n         'Age Category',\n         ['Total sum','Survived','Not Survived'],\n         title='Survived and Not-survived grouped by Age column')\n\n\nfig = make_subplots(rows=2, cols=2,\n                    specs=[[{\"colspan\": 2}, None],\n                           [{}, {}]],\n                    subplot_titles=('Age ditribution',\n                                    'Age ditribution (Survived)',\n                                    'Age ditribution (Not Survived)'))\n\nfig.add_trace(go.Histogram(x=data['Age']),\n              row=1, col=1)\n\nfig.add_trace(go.Histogram(x=data[data['target']=='Survived']['Age']),\n              row=2, col=1)\n\nfig.add_trace(go.Histogram(x=data[data['target']=='Not Survived']['Age']),\n              row=2, col=2)\n\nfig.update_layout(showlegend=False, title_text='Ditribution for Age')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fare","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=2, cols=2,\n                    specs=[[{\"colspan\": 2}, None],\n                           [{}, {}]],\n                    subplot_titles=('Fare ditribution',\n                                    'Fare ditribution (Survived)',\n                                    'Fare ditribution (Not Survived)'))\n\nfig.add_trace(go.Histogram(x=data['Fare'][:len(train)]),\n              row=1, col=1)\n\nfig.add_trace(go.Histogram(x=data[data['target']=='Survived']['Fare'][:len(train)]),\n              row=2, col=1)\n\nfig.add_trace(go.Histogram(x=data[data['target']=='Not Survived']['Fare'][:len(train)]),\n              row=2, col=2)\n\nfig.update_layout(showlegend=False, title_text='Ditribution for Fare')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extracting more relevant information by grouping by variable of interest, hueing by target variable","metadata":{}},{"cell_type":"code","source":"multi_box(data.dropna(),'Pclass','Age','target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_box(data.dropna(),'Sex','Age','target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"#some tickets only have numbers and some have initial letters+numbers. \n#I assigned 'normal' to numbers only and collected all the letters.\n\ntick=[]\n\nfor i in range(len(data['Ticket'])):\n    if len(data['Ticket'][i]) < 8:\n        tick.append('normal') \n    else:\n        tick.append(data['Ticket'][i].split(' ')[0])\n        \ndata['tickettype']=tick\n\n###\n#here I still want to save all numbers, so I will create a new list containing ticket numbers and replace the old one with this.\nticknum=[]\n\nfor i in range(len(data['Ticket'])):\n    try:\n        ticknum.append(data['Ticket'][i].split(' ')[1])\n    except:\n        ticknum.append(data['Ticket'][i])\n\n\ndata['ticket']=ticknum\ndata=data.drop('Ticket',axis=1)\n\n###\n\nfor i in range(len(data['ticket'])):\n    if data['ticket'][i].endswith('.'):\n           data['ticket'][i]=data['ticket'][i].lstrip('.') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Cabin']=data['Cabin'].replace(np.nan,'unknown')\n\nfor i in range(len(data['Cabin'])):\n    data['Cabin'][i]=data['Cabin'][i][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Embarked']=data['Embarked'].replace(np.nan, str('S')) #replaced with most common embarking spot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#extracting the unique titles\n# title_list = pd.concat([train,test])['Name'].apply(lambda x: re.findall(r'[, ]\\w+[.]',x)[0][:-1]).unique()\ntitle_list = data['Name'].apply(lambda x: re.findall(r'[, ]\\w+[.]',x)[0][:-1]).unique()\n\n# Using this iteratively I was able to get a full list of titles.\ntitle_list = ['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms','Major', \n             'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess','Jonkheer', 'Dona']\n\n \n# replacing all titles with mr, mrs, miss, master\ndef replace_titles(x):\n    title=x['Title']\n    if title in ['Don', 'Rev', 'Col','Capt','Sir','Major','Jonkheer']:\n        return 'Mr'\n    elif title in ['Countess', 'Mme']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms','Lady','Dona']:\n        return 'Miss'\n    elif title =='Dr':\n        if x['Sex']=='Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\n    \n#create a new columns containing the title for each name\ndata['Title'] = data['Name'].apply(lambda x: re.findall(r'[, ]\\w+[.]',x)[0][:-1])\n\n# apply replacing title function to all titles\ndata['Title'] = data.apply(replace_titles, axis=1)\n\n#delete name column,PassengerId,Ticket\ndel data['Name']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Age']=data['Age'].fillna(data['Age'].mean()).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets create age category\ndata['age_category'] = pd.cut(data['Age'].astype(int), bins=[-1,11,18,22,27,33,40,66,100],\n                            labels=[1,2,3,4,5,6,7,8]).to_frame()\n\n# Age times Class \n#(multiplying the age category by passenger class balances differences out in terms of importance of that person onboard)\n#although it should be reversed (class 1 is more important than class 3)\ndata['age_class'] = data['age_category']* data['Pclass']\ndata['age_class'] = data['age_class'].astype(int) \n\n# Fare per Person\ndata['fare_per_person'] = data['Fare']/(data['family count'])\ndata['fare_per_person'] = data['fare_per_person'].astype(float)  \n\n# Is alone\n#being a solo traveler decreases your chances of survival\ndata['is_alone'] = 0\ndata.loc[data['family count'] == 1, 'is_alone'] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del data['Age']\ndel data['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def readyML(df):\n    df['family count'] = df['Parch']+df['SibSp']+1 \n    df['family count'] = df['family count'].astype(int)\n\n    del df['Parch']\n    del df['SibSp']\n    tick=[]\n\n    for i in range(len(df['Ticket'])):\n        if len(df['Ticket'][i]) < 8:\n            tick.append('normal') \n        else:\n            tick.append(df['Ticket'][i].split(' ')[0])\n\n    df['tickettype']=tick\n\n    ###\n    #here I still want to save all numbers, so I will create a new list containing ticket numbers and replace the old one with this.\n    ticknum=[]\n\n    for i in range(len(df['Ticket'])):\n        try:\n            ticknum.append(df['Ticket'][i].split(' ')[1])\n        except:\n            ticknum.append(df['Ticket'][i])\n\n\n    df['ticket']=ticknum\n    df=df.drop('Ticket',axis=1)\n\n    ###\n\n    for i in range(len(df['ticket'])):\n        if df['ticket'][i].endswith('.'):\n               df['ticket'][i]=df['ticket'][i].lstrip('.') \n    df['Cabin']=df['Cabin'].replace(np.nan,'unknown')\n\n    for i in range(len(df['Cabin'])):\n        df['Cabin'][i]=df['Cabin'][i][0]\n        \n    df['Embarked']=df['Embarked'].replace(np.nan, str('S'))\n    \n    title_list = df['Name'].apply(lambda x: re.findall(r'[, ]\\w+[.]',x)[0][:-1]).unique()\n    \n    def replace_titles(x):\n        title=x['Title']\n        if title in ['Don', 'Rev', 'Col','Capt','Sir','Major','Jonkheer']:\n            return 'Mr'\n        elif title in ['Countess', 'Mme']:\n            return 'Mrs'\n        elif title in ['Mlle', 'Ms','Lady','Dona']:\n            return 'Miss'\n        elif title =='Dr':\n            if x['Sex']=='Male':\n                return 'Mr'\n            else:\n                return 'Mrs'\n        else:\n            return title\n\n    #create a new columns containing the title for each name\n    df['Title'] = df['Name'].apply(lambda x: re.findall(r'[, ]\\w+[.]',x)[0][:-1])\n\n    # apply replacing title function to all titles\n    df['Title'] = df.apply(replace_titles, axis=1)\n\n    #delete name column,PassengerId,Ticket\n    del df['Name']\n    df['Age']=df['Age'].fillna(df['Age'].mean()).astype(int)\n\n    df['age_category'] = pd.cut(df['Age'].astype(int), bins=[-1,11,18,22,27,33,40,66,100],\n                                labels=[1,2,3,4,5,6,7,8]).to_frame()\n\n    # Age times Class \n    #(multiplying the age category by passenger class balances differences out in terms of importance of that person onboard)\n    #although it should be reversed (class 1 is more important than class 3)\n    df['age_class'] = df['age_category']* df['Pclass']\n    df['age_class'] = df['age_class'].astype(int) \n\n    # Fare per Person\n    df['fare_per_person'] = df['Fare']/(df['family count'])\n    df['fare_per_person'] = df['fare_per_person'].astype(float)  \n\n    # Is alone\n    #being a solo traveler decreases your chances of survival\n    df['is_alone'] = 0\n    df.loc[df['family count'] == 1, 'is_alone'] = 1\n    del df['Age']\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=readyML(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del data['Sex']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation for ML","metadata":{}},{"cell_type":"code","source":"Y = data['target']\nX = data.drop('target', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_num=X.select_dtypes(include=np.number)\nX_cat=X.select_dtypes(exclude=np.number)\n\n#scaling the numerical columns\nfrom sklearn.preprocessing import StandardScaler \nfitted = StandardScaler().fit(X_num)\nx_scaled = fitted.transform(X_num)\nprint(x_scaled.shape)\nx_scaled=pd.DataFrame(x_scaled)\n\n#encoding the categoricals\nencoded=pd.get_dummies(X_cat, drop_first=True)\ntype(encoded)\n\nX = np.concatenate((x_scaled, encoded), axis=1)\npd.DataFrame(X).head()\nX.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split the data with train test split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building the model object\nfrom sklearn.linear_model import LogisticRegression\nlr_model = LogisticRegression()\n\n#fitting it with train data and predicting using testX\nlr_model.fit(X_train, y_train)\nY_pred = lr_model.predict(X_test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Score_Analisis(classification, X_test, y_test): #Function that tests the prediction of Logistic models with a variety of parameters\n    predictions = classification.predict(X_test) \n    print(\"Accuracy score: %4.2f \" % accuracy_score(y_test, predictions))\n    print(\"Precision score : %4.2f\" % (precision_score(y_test,predictions,pos_label='Survived')))\n    print(\"Recall score : %4.2f\" % (recall_score(y_test,predictions,pos_label='Survived')))\n    print(\"F1-score : %4.2f\" % (f1_score(y_test,predictions,pos_label='Survived')))\n    #print(\"Kappa score : %4.2f\" % (cohen_kappa_score(y_test, predictions)))\n    #print(classification_report(y_test, predictions, labels=['No', 'Yes'], zero_division = 1))\n    plot_confusion_matrix(classification, X_test, y_test) \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Score_Analisis(lr_model, X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc = RandomForestClassifier().fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Score_Analisis(rfc, X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}